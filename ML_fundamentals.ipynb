{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJIc2RLEMTlUOqH4B2dH/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dainesjeff/MLFundamentals/blob/main/ML_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3D Linear Regression (Pseudoinverse Implementation)**"
      ],
      "metadata": {
        "id": "Qy3vhV6W17sQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow**"
      ],
      "metadata": {
        "id": "xBkF6-WSWF7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "## Add checks for Data Type and shape\n",
        "\n",
        "\n",
        "def regress_with_puedoinverse(X,b):\n",
        "  pseudoinverse_X = tf.linalg.pinv(X)\n",
        "  return pseudoinverse_X @ b\n",
        "X = tf.random.uniform([10,3],minval=0, maxval = 10)\n",
        "b = tf.linspace([1], [10], 10, name=None, axis=0)\n",
        "b= tf.cast(b, X.dtype)\n",
        "a = regress_with_puedoinverse(X,b)\n",
        "\n",
        "print(X.dtype)\n",
        "print(b.shape)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLaqt6fi7Nds",
        "outputId": "aa8c3345-635c-4782-9fdf-a2bc6c6dc709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float32'>\n",
            "(10, 1)\n",
            "tf.Tensor(\n",
            "[[ 0.84599555]\n",
            " [ 0.549078  ]\n",
            " [-0.7176521 ]], shape=(3, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pytorch**"
      ],
      "metadata": {
        "id": "x8-Btf9qV5Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(43)\n",
        "\n",
        "def regress_with_puedoinverse(X,b):\n",
        "  pseudoinverse_X = torch.linalg.pinv(X)\n",
        "  return pseudoinverse_X @ b\n",
        "\n",
        "X = torch.rand(10,3) * 10\n",
        "b = torch.linspace(1,10, steps =10, dtype=X.dtype)\n",
        "b = torch.reshape(b, (10, 1))\n",
        "a = regress_with_puedoinverse(X,b)\n",
        "print(a)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtUS1_DW3C9R",
        "outputId": "2c9b387b-f464-43bd-c599-0a09b5725d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3973],\n",
            "        [0.6357],\n",
            "        [0.1045]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fully Connected MLP**"
      ],
      "metadata": {
        "id": "bW_j0xaSVxuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ucimlrepo\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# fetch dataset\n",
        "wine = fetch_ucirepo(id=109)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EuKsRLwN_v2",
        "outputId": "e8672ca5-5664-4426-9359-d58823d0f389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# targets = pd.get_dummies(wine.data.targets['class'])\n",
        "# print(targets.head())\n",
        "\n",
        "features = wine.data.features.to_numpy()\n",
        "targets = wine.data.targets.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(features, targets,test_size=0.2, train_size=0.8)\n",
        "\n",
        "train_y = tf.keras.utils.to_categorical(train_y)\n",
        "test_y = tf.keras.utils.to_categorical(test_y)\n"
      ],
      "metadata": {
        "id": "Bva3YD9uOxII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu', input_dim=13))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(.2, input_shape=(64,)))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2), metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wrGLiJ8aelF",
        "outputId": "a0a08811-3456-4ab3-f87a-f18cc0225afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12260 (47.89 KB)\n",
            "Trainable params: 12260 (47.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= train_X, y = train_y, batch_size=16, epochs=16, validation_data = (test_X, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuV1fSdOerDc",
        "outputId": "adc8565a-1668-4dc0-c236-d9bbea656881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "9/9 [==============================] - 13s 63ms/step - loss: 133.9157 - accuracy: 0.3099 - val_loss: 3.7922 - val_accuracy: 0.3056\n",
            "Epoch 2/16\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.5317 - accuracy: 0.4507 - val_loss: 1.2093 - val_accuracy: 0.3889\n",
            "Epoch 3/16\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1872 - accuracy: 0.4014 - val_loss: 1.1177 - val_accuracy: 0.3889\n",
            "Epoch 4/16\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1115 - accuracy: 0.3239 - val_loss: 1.1711 - val_accuracy: 0.2222\n",
            "Epoch 5/16\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.1098 - accuracy: 0.3592 - val_loss: 1.1171 - val_accuracy: 0.3889\n",
            "Epoch 6/16\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0888 - accuracy: 0.4014 - val_loss: 1.1050 - val_accuracy: 0.3889\n",
            "Epoch 7/16\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0827 - accuracy: 0.3451 - val_loss: 1.1387 - val_accuracy: 0.3889\n",
            "Epoch 8/16\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0776 - accuracy: 0.4014 - val_loss: 1.1527 - val_accuracy: 0.3889\n",
            "Epoch 9/16\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.0904 - accuracy: 0.3592 - val_loss: 1.1237 - val_accuracy: 0.3889\n",
            "Epoch 10/16\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.0851 - accuracy: 0.4014 - val_loss: 1.1111 - val_accuracy: 0.3889\n",
            "Epoch 11/16\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1.0904 - accuracy: 0.4014 - val_loss: 1.1258 - val_accuracy: 0.3889\n",
            "Epoch 12/16\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.0757 - accuracy: 0.4014 - val_loss: 1.1442 - val_accuracy: 0.3889\n",
            "Epoch 13/16\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.0860 - accuracy: 0.3873 - val_loss: 1.1352 - val_accuracy: 0.3889\n",
            "Epoch 14/16\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.0874 - accuracy: 0.3380 - val_loss: 1.1360 - val_accuracy: 0.3889\n",
            "Epoch 15/16\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.0799 - accuracy: 0.4014 - val_loss: 1.1244 - val_accuracy: 0.3889\n",
            "Epoch 16/16\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 1.0795 - accuracy: 0.3873 - val_loss: 1.1546 - val_accuracy: 0.3889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "slmLTzNhoSE9",
        "outputId": "6960ea43-63fe-453f-8e24-a7be8be4bcfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a5c22ad6b0be>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(13, 32)\n",
        "    self.fc2 = nn.Linear(32,64)\n",
        "    self.fc3 = nn.Linear(64,32)\n",
        "    self.out = nn.Linear(32, 4)\n",
        "\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "    nn.Linear(13, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 4)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      logits = self.linear_relu_stack(x)\n",
        "      return logits\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "model = DenseNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 16\n",
        "\n",
        "\n",
        "torch_train_X =  Variable(torch.from_numpy(train_X).float(), requires_grad=False)\n",
        "torch_train_y = Variable(torch.from_numpy(train_y), requires_grad=False)\n",
        "train_dataset = torch.utils.data.TensorDataset(torch_train_X, torch_train_y)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "for i in range(epochs):\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "8wqzmYZoRw7z",
        "outputId": "7b19e7f3-e516-4e05-afd9-dc7c58f50163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-73687c858b6b>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtorch_train_X\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtorch_train_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
          ]
        }
      ]
    }
  ]
}